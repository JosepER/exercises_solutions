---
title: Solutions to exercises in Data Analysis Using Regression and Multilevel/Hierarchical
  Models by Gelman and Hill (2006)
output:
  html_document: default
  html_notebook: default
---

```{r, warning=FALSE, message=FALSE}

library(rebus)
library(stringr)
library(rvest)
library(magrittr)
library(tidyverse)

```


# Chapter 2

##Exercise 1

**1.A test is graded from 0 to 50, with an average score of 35 and a standard deviation of 10. For comparison to other tests, it would be convenient to rescale to a mean of 100 and standard deviation of 15.**

**a) How can the scores be linearly transformed to have this new mean and standard deviation?**

We know that the standard deviation of the rescaled grades should be $b = \sigma_1 / \sigma_2 = 15/10 = 1.5$ times larger than the original one. This means that we need to multiply the original grades by this factor and add a constant that makes the rescaled grades mean equal to the target mean of 100. 

In other words, we should solve the equation: 
$$ \mu_2 = a + b \times \mu_1  $$
$ 100 = a + 1.5 \times 35 $ Therefore $ a = 100 - 1.5\times 35 \approx 47.5 $

The transformation should then be equal to $ y = 47.5 + 1.5 x $ where x is the original vector of grades and y the rescaled one.

We can try this using simulated data.

Here we create 2000 observations from a normal distribution with mean 35 and standard deviation of 10.
```{r, warning=FALSE, message=FALSE}

set.seed(4)

grades. <- rnorm(2000, mean = 35, sd = 10)

```


```{r, warning=FALSE, message=FALSE}

grades. %>% mean() %>% round(0)

grades. %>% sd() %>% round(0)

```

Here we rescale the previous simulated data to give it the desired mean and standard deviation.
```{r, warning=FALSE, message=FALSE}

resc.grades. <- grades. * 15/10 + (100-mean(grades.)*1.5) 

resc.grades. %>% mean() %>% round(0)

resc.grades. %>% sd() %>% round(0)

```

**b) There is another linear transformation that also rescales the scores to have mean 100 and standard deviation 15. What is it, and why would you _not_ want to use it for this purpose?** 

Apparently, we could use a negative factor for the linear tranformation.^[https://stats.stackexchange.com/questions/45816/gelman-hill-textbook-question-about-linear-transformation] This would follow the equation: $$y = a -b \times x$$

Therefore it would be $100 = a -1.5 \times 35$ and $a = 152.5$.

Let's see what happens when we use this transformation to rescale our simulated data.
```{r, warning=FALSE, message=FALSE}

resc.grades.b. <- grades. * (-1.5) + (100-mean(grades.)*(-1.5))

```

```{r, warning=FALSE, message=FALSE}

resc.grades.b. %>% mean() %>% round(0)

resc.grades.b. %>% sd() %>% round(0)

```

The mean and standard deviation seem to be the desired ones. What's wrong then?
```{r, warning=FALSE, message=FALSE}

data_frame(grades. = grades. %>% round(0), resc.grades. = resc.grades. %>% round(0), resc.grades.b. = resc.grades.b. %>% round(0))

```

Surprise, surprise. The second transformation actually inverted the distribution around the mean. Both _'resc.grades.'_ and _'resc.grades.b.'_ have mean 100. However, using a negative factor in the equation 'mirrored' the observations. I.e. it placed below the mean those that were initially above it and viceversa. This is why we do not want to use it for this purpose. We don't want the student with the best grade to have the lowest score after transformation, do we?

```{r, warning=FALSE, message=FALSE}

rm(grades., resc.grades., resc.grades.b.)

```


##Exercise2 
**The following are the proportions of girl births in Vienna for each month in 1908 and 1909 (out of an average of 3900 births per month):**

```{r, warning=FALSE, message=FALSE}

girls.html. <- html("http://www.stat.columbia.edu/~gelman/arm/examples/girls/births.txt") %>% 
  html_text()

```

```{r, warning=FALSE, message=FALSE}

girls.html. %<>%
  str_match_all(pattern = ("\\t." %R% capture(DGT %R% DGT %R% DGT %R% DGT)))

girls.html. <- girls.html.[[1]][1:24,2]

girls.html. %<>%
  str_c("0.", .) %>%
  as.numeric()

```

**a) Compute the standard deviation of these proportions and compare to the standard deviation that would be expected if the sexes of babies were independently decided with a constant probability over the 24-month period.**

The standard deviation in from births in Vienna is `r sd(girls.html.)`. The standard deviation we would expect from a binomial distribution is with probability equal to the mean of the data is `r sqrt((mean(girls.html.))*(1-mean(girls.html.))/23)`.

```{r, warning=FALSE, message=FALSE}

s. <- sd(girls.html.)

sigma. <- sqrt((mean(girls.html.))*(1-mean(girls.html.))/23)

s.

sigma.

```

**b) The actual and theoretical standard deviations from (a) differ, of course. Is this difference statistically significant? (Hint: under the randomness model, the actual variance should have a distribution with expected value equal to the theoretical variance, and proportional to a Ï‡2 with 23 degrees of freedom.)**

The exercise is basically asking us to check if the difference between the variance observed and the variance we would expect from a binomial distribution is large enough as not to have been caused by sampling error (i.e. by the fact that we only have 24 observations from the distribution behind the data).

Here we want to test the plausibility of the null hypothesis that the observed variance is equal to the theoretical/expected variance: 
$$H_0: \sigma^2 = \sigma^2_0   $$
The test statistic is: $$T = (N-1)(s / \sigma_0)^2$$

Where _N_ is the sample size, and $s / \sigma_0$ is the ratio between the sample standard deviation and the theoretical standard deviation.

More information about the test can be found in the following [webpage](http://www.itl.nist.gov/div898/handbook/eda/section3/eda358.htm)
```{r, warning=FALSE, message=FALSE}

T <- (length(girls.html.)-1)*(s./sigma.)^2

T

```

At a 5% confidence level with a two-tailed test, we would reject the null hypothesis if
T was smaller than the value in the Chi squared distribution with 23 df.

```{r, warning=FALSE, message=FALSE}

qchisq(0.975, 23, ncp = 0, log = FALSE)

```

Therefore, here we would reject the null hypotheses and retain the alternative hypothesis. I.e. the sample variance is smaller than what we would expect from a binomial distribution.

_Note: As I'm not sure about this answer and I've found different solutions online when double-checking my response, I will compute simulations._

See for example solutions by others: [here](https://github.com/IamGianluca/arm/blob/master/ch2/Ch2_2.ipynb) and [here](https://raw.githubusercontent.com/Fossj117/gelman_hill/master/Ch2/Ch2_ex.md)

```{r, warning=FALSE, message=FALSE}

mean.girls. <- girls.html. %>% mean()

number.simulated.twoyears <- 100000

simulated.months. <- rep(NA, 24*number.simulated.twoyears)

if(!"simulated_months_2_2.RDS" %in% list.files("interim_outputs/")){

for(i in 1:(24*number.simulated.twoyears)){

simulated.months.[i] <- rbinom(3903, 1, mean.girls.) %>% mean()

}

saveRDS(simulated.months., "interim_outputs/simulated_months_2_2.RDS")
}else{simulated.months. <- readRDS("interim_outputs/simulated_months_2_2.RDS")}

sim.twoyear.number <- rep(1:(length(simulated.months.)/24), 24) %>% sort()

sim.month.number <- rep(1:24, length(simulated.months.)/24)

simulated.twoyears <- data_frame(sim.twoyear.number, sim.month.number, simulated.months.) %>% arrange(sim.twoyear.number, sim.month.number)

simulated.twoyears

```

```{r, warning=FALSE, message=FALSE}

simulated.twoyears.sd <- simulated.twoyears %>%
  group_by(sim.twoyear.number) %>%
  summarise(simulated.sd = sd(simulated.months.))

simulated.twoyears.sd

```

```{r, warning=FALSE, message=FALSE}

quantile(simulated.twoyears.sd$simulated.sd, probs = c(0.025, 0.975)) 

s.

```

Compute graph!